{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DSPT6_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnthonyJFeola/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module1-rnn-and-lstm/LS_DSPT6_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxU8ZqqrVrka"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "86XFPZwgVrkb"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "e7SXjVI0Vrke"
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "7CPwcLEdVrkh",
        "outputId": "d0c8b03a-91c8-492d-9535-fdbed32b530b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "print(df_toc.shape)\n",
        "df_toc.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(43, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\n\\n\\nDRAMATIS PERSONAE.\\n\\n  DU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\n\\n\\n\\nContents\\n\\nACT I\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\n\\nDramatis Personae...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\nLaud we the gods;\\nAnd let our cro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\n\\n\\nDRAMATIS PERSONAE.\\n\\n  DU...\n",
              "2                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\n\\n\\n\\nContents\\n\\nACT I\\...\n",
              "3            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\n\\nDramatis Personae...\n",
              "4                            CYMBELINE  ...  CYMBELINE.\\nLaud we the gods;\\nAnd let our cro...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dps_SRnJWSo9"
      },
      "source": [
        "# Get all text\n",
        "text = \" \".join(df_toc['text'])\n",
        "\n",
        "# Get unique characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Make character and index lookup tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6Vwv6S2ZoHK",
        "outputId": "7c867d7d-d6ae-4906-a369-aa9de2942385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "maxlen = 70\n",
        "step = 20\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 70 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('Sequences:', len(sequences))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequences: 737749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVrf7mYDlz2R",
        "outputId": "06bb1ff1-6d84-4511-f4e3-8298add14848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[49,\n",
              " 7,\n",
              " 78,\n",
              " 49,\n",
              " 12,\n",
              " 11,\n",
              " 64,\n",
              " 49,\n",
              " 103,\n",
              " 94,\n",
              " 90,\n",
              " 75,\n",
              " 49,\n",
              " 94,\n",
              " 82,\n",
              " 40,\n",
              " 40,\n",
              " 40,\n",
              " 89,\n",
              " 70,\n",
              " 7,\n",
              " 25,\n",
              " 7,\n",
              " 82,\n",
              " 94,\n",
              " 78,\n",
              " 49,\n",
              " 35,\n",
              " 75,\n",
              " 70,\n",
              " 78,\n",
              " 11,\n",
              " 50,\n",
              " 7,\n",
              " 75,\n",
              " 21,\n",
              " 40,\n",
              " 40,\n",
              " 49,\n",
              " 49,\n",
              " 89,\n",
              " 64,\n",
              " 90,\n",
              " 75,\n",
              " 36,\n",
              " 49,\n",
              " 54,\n",
              " 37,\n",
              " 45,\n",
              " 37,\n",
              " 100,\n",
              " 22,\n",
              " 49,\n",
              " 37,\n",
              " 100,\n",
              " 49,\n",
              " 96,\n",
              " 55,\n",
              " 37,\n",
              " 54,\n",
              " 96,\n",
              " 40,\n",
              " 49,\n",
              " 49,\n",
              " 2,\n",
              " 70,\n",
              " 75,\n",
              " 89,\n",
              " 75,\n",
              " 70]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JftSIBsIcpTY"
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97_b5vQbcy7U",
        "outputId": "fce89ec3-0fc0-4103-fd3d-25fa257f4fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(737749, 70, 105)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXiCBd9Sdj-E",
        "outputId": "fc014f49-2673-4a37-e9cc-e43b3ecde16d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(737749, 105)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES_L-jqmexuW"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs58BnYWeyV6"
      },
      "source": [
        "# LECTURE FUNCTION\n",
        "\n",
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N22XYiiPe0RL"
      },
      "source": [
        "# LECTURE FUNCTION\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8einmIZe2tm",
        "outputId": "4ca49292-0260-45ff-f1bc-4b2b9fc943a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "23054/23055 [============================>.] - ETA: 0s - loss: 2.0948\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"nother bad match, a bankrupt, a prodigal, who dare scarce\n",
            "show his hea\"\n",
            "nother bad match, a bankrupt, a prodigal, who dare scarce\n",
            "show his hear dive the formyied's hat-ander and kind of\n",
            "Angure se ond kan yet come’d\n",
            "I as groel see end him. wiring Hits be of thy King a nogre of whorts\n",
            "Thele leralay-forame to hay four womengly lofk.\n",
            "\n",
            "LUNSD]\n",
            "What newh mad! Life, a) If ho nother for ownane\n",
            "    Wirsbure the mo;t to math to make.\n",
            "    He came kneese the eard of neay in syoued ?\n",
            "    Thais I’ thing yut your well\n",
            "    Ardeed thy fafosucida, and sie\n",
            "23055/23055 [==============================] - 142s 6ms/step - loss: 2.0948\n",
            "Epoch 2/10\n",
            "23053/23055 [============================>.] - ETA: 0s - loss: 1.7596\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \";\n",
            "    Dispersed are the glories it included.\n",
            "    Now am I like that pr\"\n",
            ";\n",
            "    Dispersed are the glories it included.\n",
            "    Now am I like that pretice the let thee werr\n",
            "    Is the swor! sheire he have wencle formon by bether\n",
            "To feir your tame at wore! are me not sheet:\n",
            "Proptos, we new you she day is days imp'ry\n",
            "Madyyer give you house tell vestipaking allitys in a woust\n",
            "To some fell distress tells!\n",
            "\n",
            " [_Heright and Joverouch._] Haft is there’s fatlanst in very\n",
            "Wollore, do you koad? Ore pastelly here well,\n",
            "Fiel, as the conso tern horfibed;\n",
            "As\n",
            "23055/23055 [==============================] - 141s 6ms/step - loss: 1.7596\n",
            "Epoch 3/10\n",
            "23049/23055 [============================>.] - ETA: 0s - loss: 1.6519\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"ke such a fellow?\n",
            "\n",
            "MERCUTIO.\n",
            "Come, come, thou art as hot a Jack in thy\"\n",
            "ke such a fellow?\n",
            "\n",
            "MERCUTIO.\n",
            "Come, come, thou art as hot a Jack in thy ewex.\n",
            "\n",
            "here now, are hould in a lake us us a\n",
            "non ala with the fint alrice.\n",
            "\n",
            "CASSIO\n",
            "\n",
            "Scenot.\n",
            "\n",
            "ECRSELO.\n",
            "A ole thou lame, not meet.\n",
            "\n",
            "POUTLIO.\n",
            "How, such year, and my clarch, father colmbret us.\n",
            "\n",
            "PUGE.\n",
            "Being all the life; who whire sumble agaies\n",
            "Yout inceorith shall preas. If thy woulder shield.\n",
            "  GLAUCESTERGH. What slefien, to with entidering\n",
            "'s me; affort, where is nepp; shall heere, 'triantuo.\n",
            "\n",
            "HES\n",
            "23055/23055 [==============================] - 142s 6ms/step - loss: 1.6518\n",
            "Epoch 4/10\n",
            "23055/23055 [==============================] - ETA: 0s - loss: 1.5895\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"e each one meetes.  [Exeunt severally.]\n",
            "\n",
            "ACT II\n",
            "\n",
            "SCENE 1.  (Athens.  A\"\n",
            "e each one meetes.  [Exeunt severally.]\n",
            "\n",
            "ACT II\n",
            "\n",
            "SCENE 1.  (Athens.  Agard-ope.\n",
            "  MARCETHIO. No!\n",
            "    Hill we move is need-like and dispetrece of him;\n",
            "    I dow scorn Lady, my lord?\n",
            "  MARIA. It the neme and with such us hine,\n",
            "    Eves God neil? 15, but if No, whot the Duke of honour;\n",
            "    Sorill with my fought undyell.\n",
            "  COND RICHARD. So, Dolix my servica's such effect; sue\n",
            "    O, give commond of so ecterous and?\n",
            "  DUKE. Wruth a mount the leck upon you with your own g\n",
            "23055/23055 [==============================] - 140s 6ms/step - loss: 1.5895\n",
            "Epoch 5/10\n",
            "23051/23055 [============================>.] - ETA: 0s - loss: 1.5476\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"Will keep a league till death. Hie thee to France,\n",
            "    And cloister th\"\n",
            "Will keep a league till death. Hie thee to France,\n",
            "    And cloister that parble paver my should don'st\n",
            "    For wemstlerd, non to wargion his virtuy; the found no; you.\n",
            "  RATHOLINUS. Be you anot so kind; here is knickly, fiin eyge sworn;\n",
            "          a hunple her present fathter servent of the mishowr! Rother! I do you now\n",
            "Iffollo, in hore hearton master. Glad, wass from thee with\n",
            "Miles Gods; I fortht I that Are with to the tongue\n",
            "Why, have we husband for to; which them\n",
            "23055/23055 [==============================] - 140s 6ms/step - loss: 1.5476\n",
            "Epoch 6/10\n",
            "23046/23055 [============================>.] - ETA: 0s - loss: 1.5172\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"in branches yet\n",
            "Your maidenheads growing. O Proserpina,\n",
            "From the flowe\"\n",
            "in branches yet\n",
            "Your maidenheads growing. O Proserpina,\n",
            "From the flowero’s day of verge shanoup,\n",
            "O hand, be stend-house, a divisen'd of Clay!\n",
            "\n",
            " Enter I make you.\n",
            "\n",
            "CASSIO.\n",
            "She shall scordledin; by his puts excemats,\n",
            "Those bese it the news countise.\n",
            "\n",
            "HORTILER.\n",
            "This is’s he streage, and die to have she bage\n",
            "I prophed tempedst of her hands, it in findy\n",
            "\n",
            "DAUGHTERS. The tell’d us as you loves up ancerve\n",
            "    To fion felling Englars had lords with sence;\n",
            "    All my dear in \n",
            "23055/23055 [==============================] - 141s 6ms/step - loss: 1.5171\n",
            "Epoch 7/10\n",
            "23047/23055 [============================>.] - ETA: 0s - loss: 1.4943\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"II. Bohemia. A Room in the palace of Polixenes.\n",
            "\n",
            " Enter Polixenes and \"\n",
            "II. Bohemia. A Room in the palace of Polixenes.\n",
            "\n",
            " Enter Polixenes and and Lusiention.\n",
            "\n",
            "Welland; earth, sister with thee; here a but repaure,\n",
            "Ure to he mean your dure in how: thou wiltsell'd,\n",
            "I froa forcums to bound be and of cheegl hand\n",
            "To be am’t of the mide shall teld,\n",
            "I have I happy honest so still warr'd to eyes,\n",
            "Cotwold in convetion polvatcy.\n",
            "\n",
            "OTHELLO.\n",
            "I sayqued that make. Thy theirs the hangd mockness,\n",
            "I in the selfuan'st you.\n",
            "\n",
            "TRANIO.\n",
            "Go.\n",
            "\n",
            "BULLOE.\n",
            "Tis all cou\n",
            "23055/23055 [==============================] - 141s 6ms/step - loss: 1.4943\n",
            "Epoch 8/10\n",
            "23055/23055 [==============================] - ETA: 0s - loss: 1.4758\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \" the presence of the sun,\n",
            "      Following darkness like a dream,\n",
            "   No\"\n",
            " the presence of the sun,\n",
            "      Following darkness like a dream,\n",
            "   Now dows criendem out.\n",
            "  GLOUCESTARD. Y'st.\n",
            "  VALENTINE. Nay, again, but, she is your heart.\n",
            "  ESWALD. O Make!\n",
            "  CONIN\n",
            "  NURDET. That I am not commend'd Chrrace.\n",
            "  BARDOLINA. Ours of said, this would bether.\n",
            "    Master him?\n",
            "  PRINTER. Now obey father!\n",
            "  AUGEL. What place, That whose heth moden! [ Than in voynoons,\n",
            "  PAGET. Hear Toby gentlem'd Sir\n",
            "    [They sland.\n",
            "\n",
            "\n",
            "      Forget, Noor trunk.] I will \n",
            "23055/23055 [==============================] - 139s 6ms/step - loss: 1.4758\n",
            "Epoch 9/10\n",
            "23047/23055 [============================>.] - ETA: 0s - loss: 1.9644\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"ll after kind,\n",
            "                So be sure will Rosalinde.\n",
            "            \"\n",
            "ll after kind,\n",
            "                So be sure will Rosalinde.\n",
            "              \n",
            "SEvim dinihe friyit gunst now frind Byounded si—o 'ollwing yout! Dimthe seet er,hrat affecs,\n",
            "Thost hilt leave bhamin is on seof’d\n",
            "oN,aa thi chuven it xackelc\n",
            "vo chi poad 'othress yonsteng comfar!;ar threbe sey byood fut,atead ongl. o mEs,\n",
            "Iyalell Mal of ,e\n",
            " koulr itute.inhing whoh _ Lolx  w Iil e mincit werotyebm mi ghond, at horo theE he, ahe ort ifteen min cl wind sean\n",
            "Ale,ne.    fow \n",
            "om lo c\n",
            "23055/23055 [==============================] - 139s 6ms/step - loss: 1.9646\n",
            "Epoch 10/10\n",
            "23047/23055 [============================>.] - ETA: 0s - loss: 2.0903\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"in.\n",
            "\n",
            "2. KNIGHT.\n",
            "Wee'l follow cheerefully.  [A great noise within cryin\"\n",
            "in.\n",
            "\n",
            "2. KNIGHT.\n",
            "Wee'l follow cheerefully.  [A great noise within cryinfes’sbluiced on bougl\n",
            "  Jeathlles ofult shamagouringright haak it list\n",
            "Blowg mander to hom oncac'll, he dems?\n",
            "\n",
            "LEON.\n",
            "Shar;\n",
            "                What.\n",
            "  HEBSARE.\n",
            "  ELS_ mongo,\n",
            "       Drit mo hiss,\n",
            "    He share benightsh whe'd of so mis? Sey.\n",
            "    Even his oth these she, thy sunce of in lean\n",
            "Wert he his ineve stome\n",
            "Toount; beover uppere him doey omong.\n",
            "  SIROGUNA:\n",
            "               Butnterine in georn fores;\n",
            "23055/23055 [==============================] - 140s 6ms/step - loss: 2.0902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe2806e31d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}